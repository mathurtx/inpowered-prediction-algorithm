{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##This parts reads in the files and joins them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engagements_tc = pd.read_csv('engagements_tc.txt',delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'post_id', u'events', u'engagement_date'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print engagements_tc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel/__main__.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "meta_tc = pd.read_csv('meta_tc.txt',delimiter='\\t+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meta_tc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meta_tc.set_index('post_id',inplace=True)\n",
    "engagements_tc.set_index('post_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engagements_meta = pd.merge(meta_tc,engagements_tc,how='inner',left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'link', u'title', u'summary', u'author_actor_id', u'pub_date',\n",
       "       u'events', u'engagement_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engagements_meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engagements_meta['engagement_date'] = engagements_meta['engagement_date'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "link                object\n",
       "title               object\n",
       "summary             object\n",
       "author_actor_id    float64\n",
       "pub_date            object\n",
       "events               int64\n",
       "engagement_date    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engagements_meta.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convertEngagementDate(x):\n",
    "    x[6] = datetime.fromtimestamp(x[6]).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    #x[6] = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(x[6]))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engagements_meta = engagements_meta.apply(convertEngagementDate,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convertPubDate(x):\n",
    "    x[4] = datetime.strptime(x[4], \"%Y-%m-%d %H:%M:%S\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "link                object\n",
       "title               object\n",
       "summary             object\n",
       "author_actor_id    float64\n",
       "pub_date            object\n",
       "events               int64\n",
       "engagement_date     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engagements_meta.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engagements_meta = engagements_meta.apply(convertPubDate,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "link                       object\n",
       "title                      object\n",
       "summary                    object\n",
       "author_actor_id           float64\n",
       "pub_date           datetime64[ns]\n",
       "events                      int64\n",
       "engagement_date            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dateDifference(x): \n",
    "    x[6] = datetime.strptime(str(x[6]), \"%Y-%m-%d %H:%M:%S\")\n",
    "    x[7] = abs((x[6] - x[4]).days)\n",
    "    return x\n",
    "engagements_meta.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PART 2\n",
    "# Feature Extraction\n",
    "# Since we have to find views for the first day we find the events for the first day\n",
    "# Do analysis on link url - Analysis Results : All the events came from one view\n",
    "# Find AuthorEventsRation = Views by Author/ Total number of views\n",
    "# LDA to find topics for the authors - Could not be completed because of issues with one hot encoding. If resolved could have\n",
    "# been used as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engagements_meta['date_difference'] = 1\n",
    "engagements_meta = engagements_meta.apply(dateDifference,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authorEventCount = engagements_meta.groupby('author_actor_id')['events'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authorEventCount = pd.DataFrame(authorEventCount)\n",
    "authorEventCount.columns = ['Total_events']\n",
    "authorEventCount.head(1)\n",
    "totalEventCount = authorEventCount['Total_events'].sum()\n",
    "authorEventCount.columns = ['AuthorEventsRatio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculateEventCountRatio(x):\n",
    "    x = (x*1.0)/(totalEventCount*1.0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authorEventCount = authorEventCount.applymap(lambda x : calculateEventCountRatio(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authorEventCount.head(1)\n",
    "authorEventCount.to_csv('AuthorEventsRatio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engagements_meta['post_id'] = engagements_meta.index\n",
    "engagements_meta.set_index('author_actor_id',inplace=True)\n",
    "engagements_meta_author_ratio = pd.merge(authorEventCount,engagements_meta,left_index=True,right_index=True, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'AuthorEventsRatio', u'link', u'title', u'summary', u'pub_date',\n",
       "       u'events', u'engagement_date', u'date_difference', u'post_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engagements_meta_author_ratio.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel/__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "engagements_meta_author_ratio = engagements_meta_author_ratio.sort(['AuthorEventsRatio','events'],ascending=[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Finding similarity between content of same users\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similarityDf = pd.merge(engagements_meta_author_ratio,engagements_meta_author_ratio,left_index=True,right_index=True,how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/numpy-1.11.0-py2.7-macosx-10.10-intel.egg/numpy/core/fromnumeric.py:2652: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['vectorizer.pk',\n",
       " 'vectorizer.pk_01.npy',\n",
       " 'vectorizer.pk_02.npy',\n",
       " 'vectorizer.pk_03.npy']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "vectorizer = TfidfVectorizer(min_df=1,stop_words='english',ngram_range=(2, 2))\n",
    "tfidf_1 = vectorizer.fit_transform(engagements_meta_author_ratio['summary'].values.tolist())\n",
    "joblib.dump(tfidf_1,\"vectorizer.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similarityDf = tfidf_1 * tfidf_1.T\n",
    "similarityArray = similarityDf.todense()\n",
    "postId = engagements_meta_author_ratio['post_id'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-78901d091b11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarityArray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpostId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Python/2.7/site-packages/numpy-1.11.0-py2.7-macosx-10.10-intel.egg/numpy/core/shape_base.pyc\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "np.hstack((similarityArray,postId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30209"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engagements_meta_author_ratio.to_csv('engagements_meta_author_ratio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Link Analysis - Did not give sufficient value - Events from only one url\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linkGrouping = engagements_meta_author_ratio['link']\n",
    "linkGrouping = pd.DataFrame(linkGrouping)\n",
    "linkGrouping.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urlparse import urlparse\n",
    "def extractLinkUrl(x):\n",
    "    parsed_uri = urlparse(x)\n",
    "    domain = '{uri.scheme}://{uri.netloc}/'.format(uri=parsed_uri)\n",
    "    return domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linkGrouping = linkGrouping.applymap(lambda x: extractLinkUrl(x))\n",
    "linkGrouping.drop_duplicates(['link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# START LDA WORK\n",
    "# Could not be completed because of problems with one hot encoding\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary = engagements_meta_author_ratio[['summary','post_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "summary.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary['author_actor_id'] = summary.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summaryList = summary.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summaryList[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print summaryList[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AuthorTextIndex = []\n",
    "def combineText():\n",
    "    startIndex = int(summaryList[1][1])\n",
    "    text = ''\n",
    "    for x in summaryList:\n",
    "        if int(x[1]) == startIndex:\n",
    "            text = text + x[0]\n",
    "        elif int(x[1]) != startIndex:\n",
    "            AuthorTextIndex.append((startIndex,text))\n",
    "            startIndex = int(x[1])\n",
    "            text = x[0]\n",
    "\n",
    "combineText()          \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(AuthorTextIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AuthorTextIndex[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=1,stop_words='english',ngram_range=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AuthorText = [x[1] for x in  AuthorTextIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(AuthorText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AuthorTextVectorizer = vectorizer.fit_transform(AuthorText)\n",
    "idf = vectorizer.idf_\n",
    "idf.sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nmf = NMF(n_components=10, random_state=1, alpha=.1, l1_ratio=.5).fit(AuthorTextVectorizer)\n",
    "topicList = []\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        s = \" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        topicList.append(s)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_topics=1000, max_iter=5,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=1000,\n",
    "                                stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(AuthorText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "label_encoder_list = \" \".join(topicList)\n",
    "label_encoder_list = label_encoder_list.split(' ')\n",
    "len(label_encoder_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le.fit(label_encoder_list)\n",
    "label_encoder_set = set(label_encoder_list)\n",
    "label_encoder_df = pd.DataFrame(list(label_encoder_set))\n",
    "label_encoder_df.to_csv('label_encoder.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AuthorTextCopy = [unicode(x[0],\"utf-8\") for x in summaryList]\n",
    "summaryReducedTopics = []\n",
    "for x in AuthorTextCopy:\n",
    "    tempList = x.split(\" \")\n",
    "    topicReduced = \" \".join([str(val) for val in tempList if val in label_encoder_list])\n",
    "    if topicReduced != '':\n",
    "        summaryReducedTopics.append(topicReduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(le, 'lda.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le.transform(summaryReducedTopics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engagements_meta_author_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasetDf = engagements_meta_author_ratio[(engagements_meta_author_ratio['date_difference'] <= 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasetDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# BUILDING THE REGRESSION MODEL\n",
    "# Using SVR with Rbf as final model\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasetDf = datasetDf[['AuthorEventsRatio','summary','date_difference','events','post_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#enc.categorical_features()\n",
    "ohefeatures = []\n",
    "for x in AuthorTextCopy:\n",
    "    tempList = x.split(\" \")\n",
    "    topicReduced = [val for val in tempList if val in label_encoder_list]\n",
    "    if topicReduced != '':\n",
    "        ohefeatures.append(topicReduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ohefeaturesFlattened = sum(ohefeatures,[])\n",
    "#enc.fit(ohefeatures)\n",
    "#enc_topics = enc.transform(summaryReducedTopics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc = preprocessing.LabelEncoder()\n",
    "list(set(ohefeaturesFlattened))\n",
    "ohefeaturesArray = list(set(ohefeaturesFlattened))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ohefeaturesArray\n",
    "#enc.fit(ohefeaturesArray)\n",
    "enc.fit(ohefeaturesArray)\n",
    "enc.transform(ohefeatures)\n",
    "#ohefeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasetDf['author_actor_id'] = datasetDf.index\n",
    "X = datasetDf[['author_actor_id','date_difference','AuthorEventsRatio']]\n",
    "X = X.values.tolist()\n",
    "X = np.array(X)\n",
    "print similarityDf.shape\n",
    "print X.shape\n",
    "X = np.hstack((X,similarityDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "y = datasetDf['events']\n",
    "y = y.values.tolist()\n",
    "y = np.array(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "svr = GridSearchCV(SVR(kernel='rbf', gamma=0.1), cv=5,\n",
    "                   param_grid={\"C\": [1e0, 1e1, 1e2, 1e3],\n",
    "                               \"gamma\": np.logspace(-2, 2, 5)})\n",
    "kr = GridSearchCV(KernelRidge(kernel='rbf', gamma=0.1), cv=5,\n",
    "                  param_grid={\"alpha\": [1e0, 0.1, 1e-2, 1e-3],\n",
    "                              \"gamma\": np.logspace(-2, 2, 5)})\n",
    "svr.fit(X_train, y_train)\n",
    "kr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_svr = svr.predict(X_test)\n",
    "y_pred_kr = kr.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print metrics.mean_squared_error(y_test,y_pred_svr)\n",
    "print metrics.mean_squared_error(y_test,y_pred_kr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Since svr with rbf gives better performance we save the svr model\n",
    "joblib.dump(svr,\"svr.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
